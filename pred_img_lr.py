import tensorflow as tf
import os
#os.environ['CUDA_VISIBLE_DEVICES'] = ''
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import mpl_toolkits.axes_grid1.inset_locator as mpl_il
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from data_generator import get_file_list
from autoencoder_hr import psnr
from predict_img import ssimiq, ssimiq_datasets
from tensorflow.keras.models import Model
from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, UpSampling2D, add

def preprocess_image(image):
    """
    Preprocesses an input image tensor by resizing it to a target size of 256 x 256.
    
    Args:
    - image: An input image tensor.
    
    Returns:
    - resized_image: A resized image tensor.
    """
    resized_image = tf.image.resize(image, [256, 256])
    return resized_image

def preprocess_batches(image_gen):
    """
    Preprocesses the batches of images generated by `image_gen`.

    Args:
        image_gen: An image generator that yields batches of images.

    Yields:
        A tuple containing the preprocessed input images and the corresponding target images.
    """
    for x_batch, y_batch in image_gen:
        x_batch = preprocess_image(x_batch)
        yield x_batch, y_batch

def lr_ae_train(train_samples, val_samples, train_img_gen, val_img_gen, fig_path, batch_size):
    """Trains an autoencoder model on super-resolution tasks.

    Args:
        train_samples (int): The total number of training samples.
        val_samples (int): The total number of validation samples.
        train_img_gen (generator): The training image generator.
        val_img_gen (generator): The validation image generator.
        model_path (str): The file path to save the trained model.
        fig_path (str): The file path to save the training plot.
        batch_size (int): The batch size for training.

    Returns:
        The trained autoencoder model.
    """
    # Define the model architecture
    input_img = Input(shape=(256, 256, 3))

    # Encoder layers
    l1 = Conv2D(64, (3, 3), padding='same', activation='relu')(input_img)
    l2 = Conv2D(64, (3, 3), padding='same', activation='relu')(l1)
    l3 = MaxPooling2D(padding='same')(l2)
    l3 = Dropout(0.3)(l3)
    l4 = Conv2D(128, (3, 3),  padding='same', activation='relu')(l3)
    l5 = Conv2D(128, (3, 3), padding='same', activation='relu')(l4)
    l6 = MaxPooling2D(padding='same')(l5)

    # Bottleneck layer
    l7 = Conv2D(256, (3, 3), padding='same', activation='relu')(l6)

    # Decoder layers
    l8 = UpSampling2D()(l7)
    l9 = Conv2D(128, (3, 3), padding='same', activation='relu')(l8)
    l10 = Conv2D(128, (3, 3), padding='same', activation='relu')(l9)
    l11 = add([l5, l10])
    l12 = UpSampling2D()(l11)
    l13 = Conv2D(64, (3, 3), padding='same', activation='relu')(l12)
    l14 = Conv2D(64, (3, 3), padding='same', activation='relu')(l13)
    l15 = add([l14, l2])

    decoded = Conv2D(3, (3, 3), padding='same', activation='relu')(l15)

    autoencoder = Model(input_img, decoded)

    # Compile the model
    autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=[psnr])

    autoencoder.summary()

    model_path = "lr_model/autoencoder_lrimg_modified.h5"
    
    # Define the model callbacks
    checkpoint = ModelCheckpoint(model_path,
                                monitor="val_loss",
                                mode="min",
                                save_best_only = True,
                                verbose=1)

    earlystop = EarlyStopping(monitor = 'val_loss', 
                            min_delta = 0, 
                            patience = 5,
                            verbose = 1,
                            restore_best_weights = True)

    learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', 
                                                patience=3, 
                                                verbose=1, 
                                                factor=0.2, 
                                                min_lr=0.00000001)
    
    # train
    hist = autoencoder.fit(train_img_gen,
                        steps_per_epoch=train_samples//batch_size,
                        validation_data=val_img_gen,
                        validation_steps=val_samples//batch_size,
                        epochs=25, callbacks=[earlystop, checkpoint, learning_rate_reduction])

    # plot hist
    psnr_hist = hist.history['psnr']
    val_psnr = hist.history['val_psnr']
    loss = hist.history['loss']
    val_loss = hist.history['val_loss']
    epochs_range = range(1, len(hist.epoch) + 1)
    plt.figure(figsize=(15,5))
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, psnr_hist, label='Train Set')
    plt.plot(epochs_range, val_psnr, label='Validation Set')
    plt.legend(loc="best")
    plt.xlabel('Epochs')
    plt.ylabel('PSNR')
    plt.title('Model PSNR')

    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, loss, label='Train Set')
    plt.plot(epochs_range, val_loss, label='Validation Set')
    plt.legend(loc="best")
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Model Loss')
    plt.savefig(fig_path)

    return autoencoder


def pred_img_lr():
    # Set the base directory for the datasets
    base_directory = 'Datasets'

    # Set the paths for the high-res and low-res images for training and validation
    train_hires_folder = os.path.join(base_directory, 'train_hr')
    train_lowres_folder = os.path.join(base_directory, 'train_' + 'x4' + '_' + 'bic')
    val_hires_folder = os.path.join(base_directory, 'val_hr')
    val_lowres_folder = os.path.join(base_directory, 'val_' + 'x4' + '_' + 'bic')

    # Get the file lists for the training and validation datasets
    train_file_list = get_file_list(train_hires_folder, train_lowres_folder)
    val_file_list = get_file_list(val_hires_folder, val_lowres_folder)

    # Set the image data generators for training, validation and masks
    train_image_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)
    val_image_datagen = ImageDataGenerator(rescale=1./255)
    mask_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)

    # Set the batch size and target image size
    batch_size = 5
    target_size = (256,256)

    # Create image data generators for the training and validation sets
    train_hiresimage_generator = train_image_datagen.flow_from_dataframe(
            train_file_list,
            x_col='high_res',
            target_size=target_size,
            class_mode = None,
            batch_size = batch_size,
            subset='training',
            shuffle=False)

    train_lowresimage_generator = train_image_datagen.flow_from_dataframe(
            train_file_list,
            x_col='low_res',
            target_size=(64,64),
            class_mode = None,
            batch_size = batch_size,
            subset='training',
            shuffle=False)
    
    test_hiresimage_generator = train_image_datagen.flow_from_dataframe(
            train_file_list,
            x_col='high_res',
            target_size=target_size,
            class_mode = None,
            batch_size = batch_size,
            subset='validation',
            shuffle=False)

    test_lowresimage_generator = train_image_datagen.flow_from_dataframe(
            train_file_list,
            x_col='low_res',
            target_size=(64,64),
            class_mode = None,
            batch_size = batch_size,
            subset='validation',
            shuffle=False)

    val_hiresimage_generator = val_image_datagen.flow_from_dataframe(
            val_file_list,
            x_col='high_res',
            target_size=target_size,
            class_mode = None,
            batch_size = batch_size,
            shuffle=False)

    val_lowresimage_generator = val_image_datagen.flow_from_dataframe(
            val_file_list,
            x_col='low_res',
            target_size=(64,64),
            class_mode = None,
            batch_size = batch_size,
            shuffle=False)

    # Prepare the generators for the training, validation and testing sets
    train_generator = zip(train_lowresimage_generator, train_hiresimage_generator)
    val_generator = zip(val_lowresimage_generator, val_hiresimage_generator)
    test_generator = zip(test_lowresimage_generator, test_hiresimage_generator)
    
    # Get the number of samples for each dataset
    train_samples = train_hiresimage_generator.samples
    val_samples = val_hiresimage_generator.samples
    test_samples = test_hiresimage_generator.samples

    # Preprocess the image batches from the generators before training, validation, and testing.
    train_img_gen = preprocess_batches(train_generator)
    val_img_gen = preprocess_batches(val_generator)
    test_img_gen = preprocess_batches(test_generator)
    fig_path = 'lr_model/x4_bic_hist.jpg'

    # Check if the trained model file exists. If not, proceed with training.
    if not os.path.exists('lr_model/autoencoder_lrimg_modified.h5'):
        hist = lr_ae_train(train_samples, val_samples, train_img_gen, val_img_gen, fig_path, batch_size)

    name = 'bic'
    fig_path = 'lr_model'
    model_path = 'lr_model/autoencoder_lrimg_modified.h5'
    model = keras.models.load_model(model_path, custom_objects = {'psnr': psnr})

    # Get the first 2 images in the test_generator
    x_test, y_test = next(test_img_gen, 1)
    x_test = preprocess_image(x_test)
    # Predict the high-res images from the low-res images
    y_pred = model.predict(x_test)
    # Define the coordinates and size of the rectangle
    x, y = 75, 75
    width, height = 50, 50
    # Calculate the PSNR values
    psnr_values = psnr(y_test, y_pred)
    print('PSNR: %f'%psnr_values)
    mse = np.mean((y_test - y_pred)**2)
    print('MSE: %f'%mse)
    ssim_datasets = ssimiq_datasets(y_test, y_pred)
    print('SSIM: %f'%ssim_datasets)
    
    # for x_test
    print('Average Evaluation Values for x_test:')
    psnr_values = psnr(y_test, x_test)
    print('PSNR: %f'%psnr_values)
    mse = np.mean((y_test - x_test)**2)
    print('MSE: %f'%mse)
    ssim_datasets = ssimiq_datasets(y_test, x_test)
    print('SSIM: %f'%ssim_datasets)
    
    # Loop through the first 2 images and plot them along with their corresponding images and PSNR values
    for i in [2, 4]:
        fig, axs = plt.subplots(1, 3, figsize=(20, 10))
        
        # Plot the high-res image
        axs[0].imshow(y_test[i])
        axs[0].set_title('High-Res Image')
        
        # Plot the predicted image
        psnr_pred = psnr(y_test[i], y_pred[i])
        ssim_pred = ssimiq(y_test[i], y_pred[i])
        axs[1].imshow(y_pred[i])
        axs[1].set_title('Predicted Image PSNR/SSIMIQ - ' + str(psnr_pred.numpy()) + r'/' + str(round(ssim_pred,7)))
        
        # Plot the low-res image
        psnr_lr = psnr(y_test[i], x_test[i])
        ssim_lr = ssimiq(y_test[i], x_test[i])
        axs[2].imshow(x_test[i])
        axs[2].set_title('Low-Res Image PSNR/SSIMIQ - ' + str(psnr_lr.numpy()) + r'/' + str(round(ssim_lr,7)))
        
        rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='r', facecolor='none')
        for ax in axs:
            ax.add_patch(patches.Rectangle(rect.get_xy(), rect.get_width(), rect.get_height(), linewidth=1, edgecolor='r', facecolor='none'))
            ax.relim() # Update the limits of the axes
            ax.autoscale() # Auto-scale the view limits to the data
        
        # Add inset to show enlarged view of region inside rectangle
        axins = mpl_il.inset_axes(axs[0], width="40%", height="40%", loc='lower right')
        axins.imshow(y_test[i][y:y+height, x:x+width])
        axins.set_xticks([])
        axins.set_yticks([])
        
        axins = mpl_il.inset_axes(axs[1], width="40%", height="40%", loc='lower right')
        axins.imshow(y_pred[i][y:y+height, x:x+width])
        axins.set_xticks([])
        axins.set_yticks([])
        
        axins = mpl_il.inset_axes(axs[2], width="40%", height="40%", loc='lower right')
        axins.imshow(y_test[i][y:y+height, x:x+width])
        axins.set_xticks([])
        axins.set_yticks([])
        
        plt.savefig(os.path.join(fig_path, str(i) + '_' + name + '.jpg'))

pred_img_lr()